<!DOCTYPE html>
<html lang="zh-Hans">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="Kali-Hac" />



<meta name="description" content="前言希望结合自身已有的知识和相关文献，将论文以一种全面而简洁、明确而有趣的方式重新演绎一遍，亦当知识点复习。“Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.”Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ru">
<meta property="og:type" content="article">
<meta property="og:title" content="ICML 2015 | Show, Attend and Tell——Neural Image Caption Generation with Visual Attention">
<meta property="og:url" content="http://yikunhaocong.com/2018/01/20/Visual-Attention/index.html">
<meta property="og:site_name" content="Ykhc">
<meta property="og:description" content="前言希望结合自身已有的知识和相关文献，将论文以一种全面而简洁、明确而有趣的方式重新演绎一遍，亦当知识点复习。“Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.”Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ru">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SAT_1.png">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SAT_5.png">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SAT_3.png">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SAT_7.jpg">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SAT_8.jpg">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a_{1}...a_{i}...a_{L}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=z_{1}...z_{t}...z_{C}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=y_{1}...y_{t}...y_{C}">
<meta property="og:image" content="http://img.blog.csdn.net/20160525112848323">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=y_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=y_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a_{i}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=z_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a_{i}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=z_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a_{i}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a_{L}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a_{1}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=z_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=z_{1}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=z_{2}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=z_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a_{1}...a_{i}...a_{L}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a\overset{\alpha}{\rightarrow}z">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=z_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a_{i}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={\alpha}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=z_{t}={\alpha_{t}}^{T}\cdot{a}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={\alpha}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={\alpha}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=a">
<meta property="og:image" content="http://img.blog.csdn.net/20160813104012944">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={\alpha}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=h_{t-1}">
<meta property="og:image" content="http://img.blog.csdn.net/20160813194310596">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=e_{t-1}">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SAT_6.png">
<meta property="og:image" content="http://img.blog.csdn.net/20160813110405462">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=c_{t}={c}_{t-1}\odot{f}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={i}_{t}\odot{g}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=h_{t}={o}_{t}\odot{tanh}{c}_{t}">
<meta property="og:image" content="http://img.blog.csdn.net/20160813190912583">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl=h_{}\overset{NN}{\rightarrow}y_{}">
<meta property="og:image" content="http://img.blog.csdn.net/20160813191330819">
<meta property="og:image" content="http://img.blog.csdn.net/20160813200110335">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={z}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={h}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={h}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={h}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={y}_{t}">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SATT2.png">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SATT1.png">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={z}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={h}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={z}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={a}_{1}...{a}_{i}...{a}_{L}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={a}_{1}...{a}_{i}...{a}_{L}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={a}_{1}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={z}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={a}_{1}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={z}_{t}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={a}_{1}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={a}_{1}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={a}_{1}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={h}_{t}">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SATT_4.png">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={L}_{h}\epsilon\mathbb{R}^{m\times{n}}">
<meta property="og:image" content="http://chart.googleapis.com/chart?cht=tx&chl={h}_{t}">
<meta property="og:image" content="http://img.blog.csdn.net/20160813190912583">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/SAT_2.png">
<meta property="og:image" content="http://op72m4y17.bkt.clouddn.com/1.jpg">
<meta property="og:updated_time" content="2018-05-07T02:33:50.188Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ICML 2015 | Show, Attend and Tell——Neural Image Caption Generation with Visual Attention">
<meta name="twitter:description" content="前言希望结合自身已有的知识和相关文献，将论文以一种全面而简洁、明确而有趣的方式重新演绎一遍，亦当知识点复习。“Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.”Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ru">
<meta name="twitter:image" content="http://op72m4y17.bkt.clouddn.com/SAT_1.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Ykhc" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>ICML 2015 | Show, Attend and Tell——Neural Image Caption Generation with Visual Attention | Ykhc</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script>
        yiliaConfig.jquery_ui = [true, "//cdn.bootcss.com/jqueryui/1.10.4/jquery-ui.min.js", "//cdn.bootcss.com/jqueryui/1.10.4/css/jquery-ui.min.css"];
    </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.jpg" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Kali-Hac</a></h1>
        </hgroup>

        
        <p class="header-subtitle">99% of sweat plus 1% of talent</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">HOME</a></li>
                        
                            <li><a href="/archives/">POSTS</a></li>
                        
                            <li><a href="/about/">My Beliefs</a></li>
                        
                            <li><a href="/temp/">Temp Space</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa GitHub" href="https://github.com/Kali-Hac" title="GitHub"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AP-SIR模型/">(AP)SIR模型</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Action-Classification/">Action Classification</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Aes-128-cbc对称加密/">Aes-128-cbc对称加密</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/AndroidSQLite简单应用/">AndroidSQLite简单应用</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Attention-Mechanism/">Attention Mechanism</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Barnes–Hut-Force-Calculation/">Barnes–Hut Force Calculation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C-库配置与使用/">C++库配置与使用</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN-RNN/">CNN & RNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNN-RNN-LSTM/">CNN/RNN-LSTM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSS/">CSS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Continuous-Emotion-Prediction/">Continuous Emotion Prediction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CryptoJS/">CryptoJS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DMHS-SMPL/">DMHS & SMPL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DMHSPV-H80KPartial/">DMHSPV & H80KPartial</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DNS/">DNS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Feedforward-Feedback-Model/">Feedforward-Feedback Model</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Force-Directed-Algorithms/">Force-Directed Algorithms</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/GPS定位/">GPS定位</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/">Git</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/HTTP-WebSocket/">HTTP/WebSocket</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hexo/">Hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Hungarian-algorithm/">Hungarian algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Image-Caption/">Image Caption</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Inter-TBB/">Inter_TBB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JavaScript/">JavaScript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/K-Anonymity/">K-Anonymity</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/K-Means/">K-Means++</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kali-linux/">Kali-linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kinematic-tree/">Kinematic tree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MSRA/">MSRA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mac/">Mac</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Markdown/">Markdown</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Monte-Carlo-Tree-Search/">Monte Carlo Tree Search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Msfvenom/">Msfvenom</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Multi-arms-Bandit-Problems/">Multi-arms Bandit Problems</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Multiple-Scene-Constraints/">Multiple Scene Constraints</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx的socket转发/">Nginx的socket转发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Payloads/">Payloads</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Quadtree/">Quadtree</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Reinforcement-learning/">Reinforcement learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SMS功能/">SMS功能</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Skeleton-Reconstruction/">Skeleton Reconstruction</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Software/">Software</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sublime/">Sublime</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Supervised-learning/">Supervised learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Table/">Table</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Telnet/">Telnet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Upper-Bounded-Confidence-UBC/">Upper Bounded Confidence(UBC)</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Upper-Confidence-Bound/">Upper Confidence Bound</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VS内置OpenMP/">VS内置OpenMP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/VarUBC/">VarUBC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Windows/">Windows</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/object-Object/">[object Object]</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/a-A-Neural-Net-Logistic-Regression/">a.A Neural Net(Logistic Regression)</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/b-Shallow-Deep-Neural-Nets/">b.Shallow/Deep Neural Nets</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c-Regularization/">c.Regularization</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/cookie验证/">cookie验证</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/d-Optimization-Algorithms/">d.Optimization Algorithms</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/e-Hyperparameters-Tuning/">e.Hyperparameters Tuning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/express/">express</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/f-F1-ROC-AUC-Error-Analysis/">f.F1/ROC/AUC/Error Analysis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/font-family/">font-family</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/g-Transfer-Multitask-End-To-End-Learning/">g.Transfer/Multitask/End-To-End Learning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/h-CNN-Padding-Stride-Filters/">h.CNN(Padding/Stride/Filters)</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/i-LeNet-5-AlexNet-VGG-16/">i.LeNet-5/AlexNet/VGG-16</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/j-Residual-Inception-Network/">j.Residual/Inception Network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k-Detection-Recognition/">k.Detection/Recognition</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/l-RNN-LSTM-BRNN/">l.RNN(LSTM/BRNN)</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/m-NLP-Word-Embeddings/">m.NLP(Word Embeddings)</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php-curl/">php_curl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php-curl快速开发/">php_curl快速开发</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php学习-实战笔记/">php学习/实战笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/php应用脚本/">php应用脚本</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/socket-io/">socket.io</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/uWSGI与Nginx的通信/">uWSGI与Nginx的通信</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/个人信息动态交易平台/">个人信息动态交易平台</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/二进制uwsgi协议/">二进制uwsgi协议</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/作者：Hac原创/">作者：Hac原创</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/反向代理服务器/">反向代理服务器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/在线聊天-点歌系统/">在线聊天/点歌系统</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/多级页表/">多级页表</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/多进程模拟/">多进程模拟</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/安卓传感器的运用/">安卓传感器的运用</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/底层TCP即时通讯/">底层TCP即时通讯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/旁带缓冲TLB表/">旁带缓冲TLB表</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/线性加速度传感器/">线性加速度传感器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/综测系统数据爬取、自动排名/">综测系统数据爬取、自动排名</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/网络爬虫/">网络爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/脚本语言的面向对象设计/">脚本语言的面向对象设计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/自动化脚本/">自动化脚本</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/谷歌抓包分析隐藏数据/">谷歌抓包分析隐藏数据</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/负载均衡/">负载均衡</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/通讯加密的应用/">通讯加密的应用</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/页框LRU回收机制/">页框LRU回收机制</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://github.com/Kali-Hac/">My GitHub</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">“A creative man is motivated by the desire to achieve, not by the desire to beat others.” – Ayn Rand</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Kali-Hac</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.jpg" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Kali-Hac</a></h1>
            </hgroup>
            
            <p class="header-subtitle">99% of sweat plus 1% of talent</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">HOME</a></li>
                
                    <li><a href="/archives/">POSTS</a></li>
                
                    <li><a href="/about/">My Beliefs</a></li>
                
                    <li><a href="/temp/">Temp Space</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/Kali-Hac" title="GitHub"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap"><article id="post-Visual-Attention" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/01/20/Visual-Attention/" class="article-date">
      <time datetime="2018-01-20T14:53:16.000Z" itemprop="datePublished">2018-01-20</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      ICML 2015 | Show, Attend and Tell——Neural Image Caption Generation with Visual Attention
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/论文研读笔记/">论文研读笔记</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Attention-Mechanism/">Attention Mechanism</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/CNN-RNN-LSTM/">CNN/RNN-LSTM</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Image-Caption/">Image Caption</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p></p><h2 id="intro">前言</h2><br><strong>希望结合自身已有的知识和相关文献，将论文以一种全面而简洁、明确而有趣的方式重新演绎一遍，亦当知识点复习。</strong><br><a href="http://202.38.196.91/cache/7/03/www.jmlr.org/1711a288cfc28455f7a1963b65d656c6/xuc15.pdf" target="_blank" rel="external">“Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.”<br>Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, Yoshua Bengio</a><br><a id="more"></a><p></p>
<p>Xu K, Ba J, Kiros R, et al. Show, attend and tell: Neural image caption generation with visual attention[C]//International Conference on Machine Learning. 2015: 2048-2057.</p>
<h2 id="请用PC端浏览器打开"><a href="#请用PC端浏览器打开" class="headerlink" title="请用PC端浏览器打开"></a>请用PC端浏览器打开</h2><p><strong>手机浏览器不支持Google Chart的Latex公式图片生成，变量公式图片可能无法正常显示</strong></p>
<h2 id="先预览一下论文模型的成果"><a href="#先预览一下论文模型的成果" class="headerlink" title="先预览一下论文模型的成果"></a>先预览一下论文模型的成果</h2><h4 id="输入一张图片，基本准确地输出一句描述"><a href="#输入一张图片，基本准确地输出一句描述" class="headerlink" title="输入一张图片，基本准确地输出一句描述"></a>输入一张图片，基本准确地输出一句描述</h4><p><img src="http://op72m4y17.bkt.clouddn.com/SAT_1.png" alt=""></p>
<h4 id="注意力-Attention-机制聚焦不同区域对应的输出"><a href="#注意力-Attention-机制聚焦不同区域对应的输出" class="headerlink" title="注意力(Attention)机制聚焦不同区域对应的输出"></a>注意力(Attention)机制聚焦不同区域对应的输出</h4><p><img src="http://op72m4y17.bkt.clouddn.com/SAT_5.png" alt=""></p>
<h4 id="模型对比，可见当年Hard-Attention性能拔得头筹"><a href="#模型对比，可见当年Hard-Attention性能拔得头筹" class="headerlink" title="模型对比，可见当年Hard-Attention性能拔得头筹"></a>模型对比，可见当年Hard-Attention性能拔得头筹</h4><p><img src="http://op72m4y17.bkt.clouddn.com/SAT_3.png" alt=""></p>
<h2 id="这篇论文的基石"><a href="#这篇论文的基石" class="headerlink" title="这篇论文的基石"></a>这篇论文的基石</h2><h3 id="「Show-and-Tell」——图像标注（Image-Caption）任务"><a href="#「Show-and-Tell」——图像标注（Image-Caption）任务" class="headerlink" title="「Show and Tell」——图像标注（Image Caption）任务"></a>「Show and Tell」——图像标注（Image Caption）任务</h3><p>Image Caption，就是从图片中自动生成一段描述性文字，有点类似于我们小时候做过的“看图说话”。对于机器来说难度在于检测物体+理解相互关系+用适当的语言表达</p>
<h3 id="Encoder-Decoder结构"><a href="#Encoder-Decoder结构" class="headerlink" title="Encoder-Decoder结构"></a>Encoder-Decoder结构</h3><p>“最原始的RNN结构中，输入序列和输出序列必须是严格等长的。但在机器翻译等任务中，源语言句子的长度和目标语言句子的长度往往不同，因此我们需要将原始序列映射为一个不同长度的序列。Encoder-Decoder模型就解决了这样一个长度不一致的映射问题。”</p>
<ul>
<li>简而言之，就是建立一个embedding(嵌入)向量空间，将每一个词表示为这个向量空间中的一个唯一的向量，即同时满足injective(单射性，x(词)和y(向量)唯一对应)和structure-preserving(结构保存,可以理解为两个词向量空间上的几何距离远近和词义的远近满足一致性)</li>
</ul>
<p>RNN的Encoder将所有的输入“编码”成一个固定的向量表示，然后Decoder在每一步都会利用它来“译码”并输出合适的单词序列,如下所示<br><img src="http://op72m4y17.bkt.clouddn.com/SAT_7.jpg" alt="Encoder-Decoder结构"></p>
<h3 id="Show-and-Tell-A-Neural-Image-Caption-Generator"><a href="#Show-and-Tell-A-Neural-Image-Caption-Generator" class="headerlink" title="Show and Tell: A Neural Image Caption Generator"></a>Show and Tell: A Neural Image Caption Generator</h3><p>“机器翻译任务中，输入输出都是单词序列，而在Image Caption任务中，输入是图像，输出是单词序列，所以只需要将原来的Encoder RNN换成图像中使用的CNN结构，为图像提取一个“视觉特征”I，然后还是使用Decoder将这个I解码为输出序列就可以了，这就是论文《Show and Tell: A Neural Image Caption Generator》中的想法”</p>
<ul>
<li>“这篇论文可是说是Image Caption任务早期的开山之作，它把Encoder-Decoder结构做了简单修改，就在Image Caption任务上取得了较好的结果，下图是这篇论文中网络的具体结构。先看提取图像特征的CNN部分，由于这篇论文是谷歌出品的，因此这部分就使用了自家的Inception模型。再看Decoder部分，将RNN换成了性能更好的LSTM，输入还是word embedding，每步的输出是单词表中所有单词的概率，这些都是标准做法了，就不再赘述。<br><img src="http://op72m4y17.bkt.clouddn.com/SAT_8.jpg" alt="采用CNN提取特征和LSTM的结构"></li>
</ul>
<blockquote>
<p>若对以上内容存在疑惑，可以进这里补补知识<br>    <a href="https://zhuanlan.zhihu.com/p/27771046" target="_blank" rel="external">1.「Show and Tell」——图像标注（Image Caption）任务技术综述</a><br>    <a href="http://blog.csdn.net/heyongluoyao8/article/details/48636251" target="_blank" rel="external">2.循环神经网络(RNN, Recurrent Neural Networks)介绍</a><br>    <a href="https://www.jianshu.com/p/9dc9f41f0b29" target="_blank" rel="external">3.[译] 理解 LSTM 网络</a></p>
</blockquote>
<h2 id="这篇论文的模型"><a href="#这篇论文的模型" class="headerlink" title="这篇论文的模型"></a>这篇论文的模型</h2><ul>
<li>有一篇CSDN博客对这篇论文的模型进行较为详细的讲解，但是仍有不足之处(在某些说明上有有一些模糊不清的逻辑)<a href="http://blog.csdn.net/shenxiaolu1984/article/details/51493673#fn:3" target="_blank" rel="external">【图像理解】之Show, attend and tell算法详解</a>，因此本文会在此博文的基础上+原论文再引入更加形象细致的说明来完整表示整个模型。<h3 id="模型输入输出"><a href="#模型输入输出" class="headerlink" title="模型输入输出"></a>模型输入输出</h3><h2 id="请用PC端浏览器打开-1"><a href="#请用PC端浏览器打开-1" class="headerlink" title="请用PC端浏览器打开"></a>请用PC端浏览器打开</h2><strong>手机浏览器不支持Google Chart的Latex公式图片生成，变量公式图片可能无法正常显示</strong><br>输入：图像 I (彩色图像)</li>
</ul>
<p>特征(annotation)：{<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a_{1}...a_{i}...a_{L}" alt="">}</p>
<p>上下文(context)：{<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=z_{1}...z_{t}...z_{C}" alt="">}</p>
<p>输出(caption)：{<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=y_{1}...y_{t}...y_{C}" alt="">}</p>
<p><img src="http://img.blog.csdn.net/20160525112848323" alt="论文模型"></p>
<p><strong>有顺序的<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=y_{t}" alt="">组成一句“说明”(caption)。句子长度C不定。每个单词<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=y_{t}" alt="">是一个K维概率，K是词典的大小。</strong></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a_{i}" alt=""><strong>是一个D维特征，共有L个，描述图像的不同区域。</strong></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=z_{t}" alt=""><strong>也是一个D维特征，共有C个，表示每个单词对应的上下文。</strong></p>
<ul>
<li>释义<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a_{i}" alt="">是一次生成的，但单词<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=z_{t}" alt="">是逐个生成的，所以使用下标t来强调每一次估计。<ul>
<li>1.<strong>怎么理解？</strong>简而言之就是<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a_{i}" alt="">到<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a_{L}" alt="">这L个向量是在输入图片后通过CNN卷积就能得到的L个特征，这里与以往卷积提取的是最后一个全连接层的总体特征不同，这L个特征是用比较低层级的卷积得到的局部区域特征。也就是相当于把图片平均分为L个区域，模型使用的是L=14*14=196个区域，维度为512(也就是提取图片512个通道的信息)，<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a_{1}" alt="">代表的是图像第一个局部区域的特征向量也叫注释向量，以此类推。</li>
<li>2.而<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=z_{t}" alt="">这个上下文向量可以这样理解，由于模型使用了Attention机制，顾名思义就是每次识别图像的时候会聚焦在某个局部区域的对象，<strong>所以<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=z_{1}" alt="">表示的是在t1时刻所聚焦的一个图像区域，<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=z_{2}" alt="">表示的是在t2时刻所聚焦的一个图像区域…以此类推。</strong>值得说明的一点是，<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=z_{t}" alt="">是该时刻<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a_{1}...a_{i}...a_{L}" alt="">注释向量的加权总和，更形象的解释是，权重越大的部分越被注意到，因此实际上它可能同时聚焦某几个区域(有些区域的权重可能一样)。<h3 id="模型上下文生成"><a href="#模型上下文生成" class="headerlink" title="模型上下文生成 "></a>模型上下文生成 <img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a\overset{\alpha}{\rightarrow}z" alt=""></h3>如上面第二点所说，上下文向量<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=z_{t}" alt="">和<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a_{i}" alt="">维度相同都为D，而且前者是后者的加权和，权重为<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={\alpha}_{t}" alt="">,表示第t刻对应的权重，计算公式为：<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=z_{t}={\alpha_{t}}^{T}\cdot{a}" alt=""></li>
</ul>
</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={\alpha}_{t}" alt="">的维度为L=196，也就是对应一张图片的196个局部区域，记录对应的注释向量位置所获得的关注</p>
<ul>
<li><p><strong>CSDN博客里的讲解中说的是每个像素位置获得的关注，实际上应该严谨一点说成每个局部区域位置获得的关注</strong></p>
</li>
<li><p><strong>那么问题来了，权重向量<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={\alpha}_{t}" alt="">怎么获得？</strong> </p>
</li>
</ul>
<p>第一步权重完全由图像特征<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=a" alt="">决定：<br><img src="http://img.blog.csdn.net/20160813104012944" alt=""><br>接下来的每一步中，权重<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={\alpha}_{t}" alt="">都由t-1时刻的隐变量<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=h_{t-1}" alt=""><br>经过若干全连接层获得,如图所示：<br><img src="http://img.blog.csdn.net/20160813194310596" alt=""><br><strong>其中<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=e_{t-1}" alt="">代表直到t-1时刻已经存储的信息，fc里包含的是一系列需要通过训练优化的参数</strong></p>
<ul>
<li>系统的隐变量以及它衍生出来的LSTM单元里面的各个向量维度都相同都为m，在论文中没给出具体维度，但我们可以假设为m = 256维度</li>
</ul>
<h3 id="关键-隐变量生成"><a href="#关键-隐变量生成" class="headerlink" title="(关键)隐变量生成 "></a>(关键)隐变量生成 <img src="http://op72m4y17.bkt.clouddn.com/SAT_6.png" alt=""></h3><p><strong>一图说明流程足矣</strong></p>
<p><img src="http://img.blog.csdn.net/20160813110405462" alt=""></p>
<ul>
<li>如果对LSTM已经有所了解的话，这个图非常直观<ul>
<li><strong>输入i，输出o，遗忘f，候选g，还有一个存储c,都为m维向量</strong><h2 id="请用PC端浏览器打开-2"><a href="#请用PC端浏览器打开-2" class="headerlink" title="请用PC端浏览器打开"></a>请用PC端浏览器打开</h2><strong>手机浏览器不支持Google Chart的Latex公式图片生成，变量公式图片可能无法正常显示</strong><br>“存储c是LSTM的核心，由前一词的存储和当前候选g加权得到，遗忘门f控制前一词存储，输入门i控制本次候选，公式如下：</li>
</ul>
</li>
</ul>
<p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=c_{t}={c}_{t-1}\odot{f}_{t}" alt="">+<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={i}_{t}\odot{g}_{t}" alt=""></p>
<p><strong>隐状态h由存储经过变化得到，强度由输出门o控制：</strong></p>
<p><img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=h_{t}={o}_{t}\odot{tanh}{c}_{t}" alt=""></p>
<p><strong>整个LSTM构造如下:</strong><br><img src="http://img.blog.csdn.net/20160813190912583" alt=""></p>
<h3 id="句子生成"><a href="#句子生成" class="headerlink" title="句子生成 "></a>句子生成 <img src="http://chart.googleapis.com/chart?cht=tx&amp;chl=h_{}\overset{NN}{\rightarrow}y_{}" alt=""></h3><ul>
<li><strong>NN指的是Neural Network</strong>，当前隐变量h通过全连网络生成当前单词y，如图所示：<br><img src="http://img.blog.csdn.net/20160813191330819" alt=""></li>
</ul>
<h3 id="重点-带着问题回顾一下整个模型"><a href="#重点-带着问题回顾一下整个模型" class="headerlink" title="(重点)带着问题回顾一下整个模型"></a>(重点)带着问题回顾一下整个模型</h3><p><img src="http://img.blog.csdn.net/20160813200110335" alt=""></p>
<blockquote>
<p><strong>第一个问题：<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={z}_{t}" alt="">为什么和<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={h}_{t}" alt="">的维度不一样？</strong></p>
<p><strong>第二个问题:对于此模型而言，Encoder和Decoder分别是哪一部分的实现？</strong></p>
<p><strong>第三个问题:LSTM里的隐变量<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={h}_{t}" alt="">究竟蕴含着什么内容？</strong></p>
<p><strong>第四个问题:<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={h}_{t}" alt="">是如何“译码”生成t时刻单词<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={y}_{t}" alt="">的？</strong></p>
</blockquote>
<ul>
<li><strong>对于以上问题，建议多看几遍原论文代入推敲一下，毕竟读论文最重要的是带着问题去思考而不是单纯地记录，这样才能发现更有价值的东西</strong></li>
</ul>
<h3 id="几个问题的剖析"><a href="#几个问题的剖析" class="headerlink" title="几个问题的剖析"></a>几个问题的剖析</h3><ul>
<li><p>可以说这几个问题让我思索了挺久，以下是我个人的见解，可能不代表论文本身观点，如果有发现不对，请对照原论文给出充分的理由证明</p>
<ul>
<li>先看一下原论文里的LSTM结构：</li>
</ul>
</li>
</ul>
<p><img src="http://op72m4y17.bkt.clouddn.com/SATT2.png" alt="LSTM"><br><img src="http://op72m4y17.bkt.clouddn.com/SATT1.png" alt="LSTM"></p>
<p><strong>这里的W、U、Z、b分别是对应LSTM不同部分通过训练会学习到的权重参数和偏置</strong></p>
<p>从上面的式子就可以看出，每个权重参数都是对应每个向量的维度而训练生成的，<strong>首先根据这一点可以先断定维度不同对于模型的训练是毫不影响的</strong>。那么<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={z}_{t}" alt=""> 维度为m=196，而<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={h}_{t}" alt=""> 维度为n=256(原论文没给具体值，但是m和n是不同的，这两者维度的设置分别意味着什么呢？</p>
<p>这个问题的答案可以同时解决第一个和第三个问题</p>
<blockquote>
<p>首先，<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={z}_{t}" alt=""> 是基于<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={a}_{1}...{a}_{i}...{a}_{L}" alt="">的维度生成的，因为它要表示图片的上下文向量，通俗地讲就是要表示出图片要聚焦的某个部分，所以它是<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={a}_{1}...{a}_{i}...{a}_{L}" alt="">加权后的向量，<strong>试想一下，当t时刻<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={a}_{1}" alt="">权重为0.9，而其它195个局部区域部分的权重相加为0.1，那<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={z}_{t}" alt="">是不是就相当于90%的<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={a}_{1}" alt="">向量+10%的其它向量，此处就可以近似地看成<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={z}_{t}" alt="">是<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={a}_{1}" alt="">的一个表示，也就是此刻图像要聚焦的部分。</strong>那有人可能要提出疑问：就算是90%的<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={a}_{1}" alt="">向量，可是还有10%的其它向量相加，你怎么能够确保它相加后还是接近<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={a}_{1}" alt="">的表示呢？</p>
</blockquote>
<p><strong>答案是肯定的，因为这就是embedding嵌入空间的一个特性：structure-preserving(结构保存,可以理解为两个词向量空间上的几何距离远近和本义的远近满足一致性),这个嵌入空间是通过深度学习网络学习出来的，具备这个特性。我可以举个更形象的例子，NLP里面的word2vec实际上也是把每个词embedding嵌入到某个固定维度的向量空间里，满足单射性injective和这个特性,因此如果想知道两个词的词义远近，可以通过直接计算两个词向量的距离，同样，图像词义(图像和标题描述)的embedding也是如此，就算存在10%的影响，这个向量还是非常接近90%的表示</strong></p>
<blockquote>
<p>那 <img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={h}_{t}" alt=""> 这个n=256维度的隐含向量究竟表示的是啥呢？</p>
</blockquote>
<p><strong>可以理解为跟t-1时刻图像语义相关的下一时刻的256个图像语义！</strong><br>同样，光说无凭，那么就附上原论文的公式：</p>
<p><img src="http://op72m4y17.bkt.clouddn.com/SATT_4.png" alt="LSTM"></p>
<p><strong>看到了吗？</strong> <img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={L}_{h}\epsilon\mathbb{R}^{m\times{n}}" alt=""><br>n维的<img src="http://chart.googleapis.com/chart?cht=tx&amp;chl={h}_{t}" alt=""> 会最终转换为m维的注释向量(图像语义)。<strong>更简单形象地说，我们可以把h看作是跟上下文向量z有关的256个注释向量(图像语义)的独热one-hot编码(为了简化，实际上它是多位编码)，它是经过LSTM单元的记忆、过滤(强度控制)而输出的，可以直接对应生成描述性单词y，而c是中间记忆产物用于下一次生成h的思考(形象一点就是它能够联系上下文，它存的就是从一开始到现在尽可能保留的但没过滤过的内容，而h是更简洁的记忆表示，因此叫做隐含层)，所有部分(包括f,i,g,o)都是为了输出一个准确而合理的h而存在的</strong></p>
<p><img src="http://img.blog.csdn.net/20160813190912583" alt=""></p>
<ul>
<li>总而言之，h就是先经过“译码”把“多位编码”(第i位的1代表第i个图像语义要输出，0代表不需要，h可以看成是一个0/1编码的256维向量)转换为注释向量(图像语义)，<strong>然后再转换为一个输出该语义各单词的概率，再把最大概率的单词输出</strong></li>
</ul>
<p>看到这里，第一个第二个第三个第四个问题就都解决了</p>
<ul>
<li><p>Encoder是将图像各个区域特征转换为注释向量(图像语义)的CNN网络，原论文用的是Oxford VGGnet (Simonyan &amp; Zisserman, 2014)</p>
</li>
<li><p>Decoder是(循环神经网络)LSTM单元，h是LSTM中各记忆门、输出门、输入门、候选门第一次“译码”后得到的隐含向量(表示相关图像语义的集合的向量)，而经过第二次“译码”就成功翻译为与图像上下文语义相关的描述性单词(这里是通过概率最大化输出)</p>
</li>
<li><p>Attention则是用在h生成的上下文向量z,它使得h能够聚焦于图像的某一个部分而不是所有，一方面能够动态更新h里面隐含的信息而不是像SRNs那样把所有前面的信息全部隐含进来，因此有助于扩大h表示的范围；另一方面，它很好的模拟了人类的视觉直觉，使得图像描述的生成更加具有智能化，可以再看一张图：</p>
</li>
</ul>
<p><img src="http://op72m4y17.bkt.clouddn.com/SAT_2.png" alt=""></p>
<p><strong>人类会因为直觉而识别错某个物体，这个模型做到了，它的直觉不是凭空想象，而是类似于人类的直觉(将相像的物体误认了)，这个错误识别的结果实际上在侧面反映了这个模型的强大，它已经能够利用注意力机制来产生图像识别的直觉</strong></p>
<h2 id="与论文相关的一些开源-我的和其他的"><a href="#与论文相关的一些开源-我的和其他的" class="headerlink" title="与论文相关的一些开源(我的和其他的)"></a>与论文相关的一些开源(我的和其他的)</h2><p><strong>原作者开源的模型代码(Theano/Caffe框架构建)</strong><br><a href="https://github.com/kelvinxu/arctic-captions" target="_blank" rel="external">https://github.com/kelvinxu/arctic-captions</a></p>
<p><strong>基于Tensorflow框架的模型开源代码(我跑的是这个)</strong><br><a href="https://github.com/yunjey/show-attend-and-tell" target="_blank" rel="external">https://github.com/yunjey/show-attend-and-tell</a></p>
<p><strong>我对原论文的全文翻译+模型实现细节+修改后的代码仓库</strong><br><a href="https://github.com/Kali-Hac/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention" target="_blank" rel="external">https://github.com/Kali-Hac/Show-Attend-and-Tell-Neural-Image-Caption-Generation-with-Visual-Attention</a></p>
<h3 id="各位小伙伴有任何问题可以在下方留言，我会及时解答或订正"><a href="#各位小伙伴有任何问题可以在下方留言，我会及时解答或订正" class="headerlink" title="各位小伙伴有任何问题可以在下方留言，我会及时解答或订正"></a>各位小伙伴有任何问题可以在下方留言，我会及时解答或订正</h3><p><img src="http://op72m4y17.bkt.clouddn.com/1.jpg" alt=""></p>

      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2018/01/20/Visual-Attention/">ICML 2015 | Show, Attend and Tell——Neural Image Caption Generation with Visual Attention</a></p>
        <p><span>文章作者:</span><a href="/" title="回到主页">Kali-Hac</a></p>
        <p><span>发布时间:</span>2018-01-20, 22:53:16</p>
        <p><span>最后更新:</span>2018-05-07, 10:33:50</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2018/01/20/Visual-Attention/" title="ICML 2015 | Show, Attend and Tell——Neural Image Caption Generation with Visual Attention">http://yikunhaocong.com/2018/01/20/Visual-Attention/</a>
            <span class="copy-path" data-clipboard-text="原文: http://yikunhaocong.com/2018/01/20/Visual-Attention/　　作者: Kali-Hac" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2018/03/17/2018-ICM-F/">
                    (贻笑大方的论文)A Dynamic Privacy Trading System
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2017/09/19/php-spider3/">
                    趣味爬虫(下)定向爬取综测系统自身班级所有成绩并进行智育Z1分值排名
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">文章目录</strong>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#intro"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#请用PC端浏览器打开"><span class="toc-number">2.</span> <span class="toc-text">请用PC端浏览器打开</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#先预览一下论文模型的成果"><span class="toc-number">3.</span> <span class="toc-text">先预览一下论文模型的成果</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#输入一张图片，基本准确地输出一句描述"><span class="toc-number">3.0.1.</span> <span class="toc-text">输入一张图片，基本准确地输出一句描述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#注意力-Attention-机制聚焦不同区域对应的输出"><span class="toc-number">3.0.2.</span> <span class="toc-text">注意力(Attention)机制聚焦不同区域对应的输出</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#模型对比，可见当年Hard-Attention性能拔得头筹"><span class="toc-number">3.0.3.</span> <span class="toc-text">模型对比，可见当年Hard-Attention性能拔得头筹</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#这篇论文的基石"><span class="toc-number">4.</span> <span class="toc-text">这篇论文的基石</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#「Show-and-Tell」——图像标注（Image-Caption）任务"><span class="toc-number">4.1.</span> <span class="toc-text">「Show and Tell」——图像标注（Image Caption）任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Encoder-Decoder结构"><span class="toc-number">4.2.</span> <span class="toc-text">Encoder-Decoder结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Show-and-Tell-A-Neural-Image-Caption-Generator"><span class="toc-number">4.3.</span> <span class="toc-text">Show and Tell: A Neural Image Caption Generator</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#这篇论文的模型"><span class="toc-number">5.</span> <span class="toc-text">这篇论文的模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型输入输出"><span class="toc-number">5.1.</span> <span class="toc-text">模型输入输出</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#请用PC端浏览器打开-1"><span class="toc-number">6.</span> <span class="toc-text">请用PC端浏览器打开</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#模型上下文生成"><span class="toc-number">6.1.</span> <span class="toc-text">模型上下文生成 </span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#关键-隐变量生成"><span class="toc-number">6.2.</span> <span class="toc-text">(关键)隐变量生成 </span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#请用PC端浏览器打开-2"><span class="toc-number">7.</span> <span class="toc-text">请用PC端浏览器打开</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#句子生成"><span class="toc-number">7.1.</span> <span class="toc-text">句子生成 </span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#重点-带着问题回顾一下整个模型"><span class="toc-number">7.2.</span> <span class="toc-text">(重点)带着问题回顾一下整个模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#几个问题的剖析"><span class="toc-number">7.3.</span> <span class="toc-text">几个问题的剖析</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#与论文相关的一些开源-我的和其他的"><span class="toc-number">8.</span> <span class="toc-text">与论文相关的一些开源(我的和其他的)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#各位小伙伴有任何问题可以在下方留言，我会及时解答或订正"><span class="toc-number">8.1.</span> <span class="toc-text">各位小伙伴有任何问题可以在下方留言，我会及时解答或订正</span></a></li></ol></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

    <script>
        yiliaConfig.toc = ["隐藏目录", "显示目录", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"ICML 2015 | Show, Attend and Tell——Neural Image Caption Generation with Visual Attention　| Ykhc　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    
        <section class="youyan" id="comments">
	<div id="uyan_frame"></div>
    <script>
        var loadComment = function(){
            var d = document, s = d.createElement('script');
            s.src = 'http://v2.uyan.cc/code/uyan.js?uid=2128463';
            (d.head || d.body).appendChild(s);
        }
    </script>
    
    <script> loadComment(); </script>

</section>
    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2018/03/17/2018-ICM-F/" title="上一篇: (贻笑大方的论文)A Dynamic Privacy Trading System">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2017/09/19/php-spider3/" title="下一篇: 趣味爬虫(下)定向爬取综测系统自身班级所有成绩并进行智育Z1分值排名">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/07/13/AlpbaZero/">NATURE 2017 | Mastering the game of Go without human knowledge</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/12/DL-review-1/">来自灵魂画手的Deep Learning可视化汇总&解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/12/CVPR-2018-3D-Human-Sensing-Action-and-Emotion-Recognition/">CVPR 2018 | 3D Human Sensing, Action and Emotion Recognition in Robot Assisted Therapy of Children with Autism</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/08/CVPR-2018-Monocular-3D-Pose-and-Shape/">CVPR 2018 | Monocular 3D Pose and Shape Estimation of Multiple People in Natural Scenes</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/07/L2T/">ICLR 2018 | Learning to Teach 论文品读</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/29/barnes-hut/">确认过眼神，四叉树Barnes-Hut算法的py实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/24/Yifanhu_source_code/">确认下眼神，Yifanhu Layout源码解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/17/2018-ICM-F/">(贻笑大方的论文)A Dynamic Privacy Trading System</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/20/Visual-Attention/">ICML 2015 | Show, Attend and Tell——Neural Image Caption Generation with Visual Attention</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/19/php-spider3/">趣味爬虫(下)定向爬取综测系统自身班级所有成绩并进行智育Z1分值排名</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/19/php-spider2/">趣味爬虫(中)制作模拟登录并具备教务查询功能的脚本</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/18/php-spider1/">趣味爬虫(上)制作模拟登录并具备教务查询功能的脚本</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/06/djangocms-uwsgi/">利用uWSGI稳健地将Django(CMS)部署到Nginx上</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/17/p-table/">多级页表虚拟内存管理器C++、python和node.js的实现</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/27/appV3-0/">(V3.0)基于AndroidSQLite和传感器的创意app(下)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/19/app/">(V3.0)基于AndroidSQLite和传感器的创意app(上)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/30/node-js-chat/">Node.js+Express/socket.io，有点创意的动态即时聊天系统(上)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/30/node-js-chat2/">Node.js+Express/socket.io，有点创意的动态即时聊天系统(下)</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/31/tbb/">几行指令让你的C++代码速度提升100%+，了解一下？</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/25/kali-linux/">有点皮的安全渗透测试①:Kali-Linux 几行指令制作最简单的木马</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/11/public-dns/">(转)几个国内专用的公共 DNS</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/04/markdown-table-style/">(我转)Markdown 表格样式调整与自适应优化</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/02/16/front-end-tools/">(再转)前端工程化工具初选</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/01/02/hexo-comments/">(我又转)为 Hexo 主题添加评论模块 — Disqus, 多说, 友言</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/12/09/css-font-family/">(我转转转)CSS font-family 网页字体使用小结</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/11/30/sublime-config/">Sublime Text 3 使用配置与插件安装</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/11/23/git-command/">Git 基础命令与相关术语</a></li><li class="post-list-item"><a class="post-list-link" href="/2015/09/20/windows-mac-software/">自用 Windows 和 Mac 软件推荐</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2017-2019 Kali-Hac
            </div>
            <div class="footer-right">
                <a href="yikunhaocong.xyz" target="_blank" title="Contact with me">Hac's</a>  Blog Powered</a> by <a href="http://hexo.io/" target="_blank" >Hexo <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
             title: "a.article-title, .article-more-link a", 
            
             tags: ".article-tag a", 
             categories: ".article-category a, a.tag-list-link", 
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>